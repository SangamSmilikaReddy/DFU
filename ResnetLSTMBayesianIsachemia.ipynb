{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b176be-ee05-49f5-93c4-793e96135e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (10.4.0)\n",
      "Requirement already satisfied: Keras_tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from Keras_tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from Keras_tuner) (24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Keras_tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from Keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->Keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->Keras_tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->Keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->Keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->Keras_tuner) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->Keras_tuner) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Keras_tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Keras_tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Keras_tuner) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Keras_tuner) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->Keras_tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->Keras_tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->Keras_tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->Keras_tuner) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn Pillow Keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ff06a0-2b8c-46f0-972d-8f442058d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, LSTM, Dense, Dropout, BatchNormalization, Reshape\n",
    "from keras.applications import ResNet152\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner.engine.hypermodel import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2864668-9ee4-4ff0-accb-932702d44fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ischaemia Class Mapping:\n",
      "non-ischemia: 1\n",
      "ischemia: 0\n",
      "Infection Class Mapping:\n",
      "non-infection: 1\n",
      "infection: 0\n",
      "Shape of Ischaemia images array: (9870, 256, 256, 3)\n",
      "Shape of Ischaemia target labels array: (9870,)\n",
      "Shape of Infection images array: (5890, 256, 256, 3)\n",
      "Shape of Infection target labels array: (5890,)\n",
      "Ischaemia Training set shape: (6909, 256, 256, 3) (6909,)\n",
      "Ischaemia Validation set shape: (2220, 256, 256, 3) (2220,)\n",
      "Ischaemia Test set shape: (741, 256, 256, 3) (741,)\n",
      "Infection Training set shape: (4123, 256, 256, 3) (4123,)\n",
      "Infection Validation set shape: (1325, 256, 256, 3) (1325,)\n",
      "Infection Test set shape: (442, 256, 256, 3) (442,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the root directory where your image folders are located\n",
    "root_directory = \"PartB_DFU_dataset - Copy\"\n",
    "\n",
    "# Initialize lists to store image paths and corresponding class labels for both datasets\n",
    "image_paths_ischaemia = []\n",
    "categories_ischaemia = []\n",
    "image_paths_infection = []\n",
    "categories_infection = []\n",
    "\n",
    "# Iterate over each class and its subdirectories\n",
    "for class_name in [\"Infection\", \"Ischaemia\"]:\n",
    "    for augmentation_type in [\"Aug-Negative\", \"Aug-Positive\"]:\n",
    "        folder_path = os.path.join(root_directory, class_name, augmentation_type)\n",
    "        category = f\"{class_name.lower()}{'pov' if 'Positive' in augmentation_type else 'neg'}\"\n",
    "        \n",
    "        # Iterate over image files in the current directory\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".jpg\"):  # Assuming images are jpg format\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                if class_name == \"Ischaemia\":\n",
    "                    image_paths_ischaemia.append(image_path)\n",
    "                    categories_ischaemia.append(\"ischemia\" if \"Positive\" in augmentation_type else \"non-ischemia\")\n",
    "                elif class_name == \"Infection\":\n",
    "                    image_paths_infection.append(image_path)\n",
    "                    categories_infection.append(\"infection\" if \"Positive\" in augmentation_type else \"non-infection\")\n",
    "\n",
    "# Create DataFrames for each dataset\n",
    "df_ischaemia = pd.DataFrame({\"category\": categories_ischaemia, \"image_path\": image_paths_ischaemia})\n",
    "df_infection = pd.DataFrame({\"category\": categories_infection, \"image_path\": image_paths_infection})\n",
    "\n",
    "# Label encoding for Ischaemia dataset\n",
    "label_encoder_ischaemia = LabelEncoder()\n",
    "df_ischaemia['Class_Label'] = label_encoder_ischaemia.fit_transform(df_ischaemia['category'])\n",
    "print(\"Ischaemia Class Mapping:\")\n",
    "for class_label, numerical_label in zip(df_ischaemia['category'].unique(), df_ischaemia['Class_Label'].unique()):\n",
    "    print(f\"{class_label}: {numerical_label}\")\n",
    "\n",
    "# Label encoding for Infection dataset\n",
    "label_encoder_infection = LabelEncoder()\n",
    "df_infection['Class_Label'] = label_encoder_infection.fit_transform(df_infection['category'])\n",
    "print(\"Infection Class Mapping:\")\n",
    "for class_label, numerical_label in zip(df_infection['category'].unique(), df_infection['Class_Label'].unique()):\n",
    "    print(f\"{class_label}: {numerical_label}\")\n",
    "\n",
    "# Shuffle both DataFrames\n",
    "df_ischaemia = df_ischaemia.sample(frac=1).reset_index(drop=True)\n",
    "df_infection = df_infection.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Helper function to load and process images\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    target_labels = []   \n",
    "    for index, row in df.iterrows():\n",
    "        image = Image.open(row['image_path']).convert('RGB')\n",
    "        image_array = np.array(image.resize((256, 256)))  # Resize image to fit DenseNet input size\n",
    "        images.append(image_array)\n",
    "        target_labels.append(row['Class_Label'])\n",
    "    return np.array(images), np.array(target_labels)\n",
    "\n",
    "# Load images for both datasets\n",
    "images_ischaemia, target_labels_ischaemia = load_images(df_ischaemia)\n",
    "images_infection, target_labels_infection = load_images(df_infection)\n",
    "\n",
    "print(\"Shape of Ischaemia images array:\", images_ischaemia.shape)\n",
    "print(\"Shape of Ischaemia target labels array:\", target_labels_ischaemia.shape)\n",
    "print(\"Shape of Infection images array:\", images_infection.shape)\n",
    "print(\"Shape of Infection target labels array:\", target_labels_infection.shape)\n",
    "\n",
    "# Split the Ischaemia dataset\n",
    "X_train_ischaemia, X_test_ischaemia, y_train_ischaemia, y_test_ischaemia = train_test_split(\n",
    "    images_ischaemia, target_labels_ischaemia, test_size=0.3, random_state=42)\n",
    "X_val_ischaemia, X_test_ischaemia, y_val_ischaemia, y_test_ischaemia = train_test_split(\n",
    "    X_test_ischaemia, y_test_ischaemia, test_size=0.25, random_state=42)  # 0.25 * 0.3 = 0.075\n",
    "\n",
    "# Split the Infection dataset\n",
    "X_train_infection, X_test_infection, y_train_infection, y_test_infection = train_test_split(\n",
    "    images_infection, target_labels_infection, test_size=0.3, random_state=42)\n",
    "X_val_infection, X_test_infection, y_val_infection, y_test_infection = train_test_split(\n",
    "    X_test_infection, y_test_infection, test_size=0.25, random_state=42)  # 0.25 * 0.3 = 0.075\n",
    "\n",
    "print(\"Ischaemia Training set shape:\", X_train_ischaemia.shape, y_train_ischaemia.shape)\n",
    "print(\"Ischaemia Validation set shape:\", X_val_ischaemia.shape, y_val_ischaemia.shape)\n",
    "print(\"Ischaemia Test set shape:\", X_test_ischaemia.shape, y_test_ischaemia.shape)\n",
    "print(\"Infection Training set shape:\", X_train_infection.shape, y_train_infection.shape)\n",
    "print(\"Infection Validation set shape:\", X_val_infection.shape, y_val_infection.shape)\n",
    "print(\"Infection Test set shape:\", X_test_infection.shape, y_test_infection.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4264b7-cf86-4598-9718-01f68bf4a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the HyperModel class for Bayesian optimization using ResNet152\n",
    "class MyHyperModel(HyperModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "        for layer in self.base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential([\n",
    "            self.base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Reshape((8, 256)),  # Adjust the reshape dimensions based on the output size of ResNet152\n",
    "            LSTM(\n",
    "                units=hp.Int('units_1', min_value=8, max_value=64, step=8),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l2(hp.Float('l2_1', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "            LSTM(\n",
    "                units=hp.Int('units_2', min_value=8, max_value=64, step=8),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l2(hp.Float('l2_2', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "            LSTM(\n",
    "                units=hp.Int('units_3', min_value=8, max_value=64, step=8),\n",
    "                kernel_regularizer=l2(hp.Float('l2_3', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_3', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "            BatchNormalization(),\n",
    "            Dense(\n",
    "                units=hp.Int('dense_units', min_value=8, max_value=64, step=8),\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(hp.Float('l2_dense', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_dense', min_value=0.1, max_value=0.5, step=0.1)),\n",
    "            BatchNormalization(),\n",
    "            Dense(3, activation='softmax', kernel_regularizer=l2(hp.Float('l2_final', min_value=0.001, max_value=0.01, step=0.001)))\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29870bda-d754-4f3b-8883-2df84fef523e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 07:32:04.861440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22066 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-07-30 07:32:04.863635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22066 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:21:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='my_dir',\n",
    "    project_name='resnet152_optimization'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83d59ac-4be3-4c25-a815-be6cf4581f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 07m 17s]\n",
      "val_accuracy: 0.9594594836235046\n",
      "\n",
      "Best val_accuracy So Far: 0.9720720648765564\n",
      "Total elapsed time: 00h 49m 00s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "tuner.search(X_train_ischaemia, y_train_ischaemia, epochs=50, validation_data=(X_val_ischaemia, y_val_ischaemia),callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feb370d6-570d-44a7-b296-2bdf504e7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.9756 - loss: 0.1720\n",
      "Test accuracy: 0.9689608812332153\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_ischaemia, y_test_ischaemia)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70f3d2-c056-473d-890e-6359eaf97d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
