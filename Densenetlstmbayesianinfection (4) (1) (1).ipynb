{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564a4d6f-479f-4e9c-807d-9a9b07cee5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.0.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.7)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.1.8)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: pytz, kt-legacy, tzdata, threadpoolctl, scipy, pillow, joblib, scikit-learn, pandas, keras-tuner\n",
      "Successfully installed joblib-1.4.2 keras-tuner-1.4.7 kt-legacy-1.0.5 pandas-2.2.3 pillow-11.0.0 pytz-2024.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0 tzdata-2024.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn numpy pillow keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b667b5-a510-446f-ba8c-58693730a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ischaemia Class Mapping:\n",
      "non-ischemia: 1\n",
      "ischemia: 0\n",
      "Infection Class Mapping:\n",
      "non-infection: 1\n",
      "infection: 0\n",
      "Shape of Ischaemia images array: (9870, 256, 256, 3)\n",
      "Shape of Ischaemia target labels array: (9870,)\n",
      "Shape of Infection images array: (5890, 256, 256, 3)\n",
      "Shape of Infection target labels array: (5890,)\n",
      "Ischaemia Training set shape: (6909, 256, 256, 3) (6909,)\n",
      "Ischaemia Validation set shape: (2220, 256, 256, 3) (2220,)\n",
      "Ischaemia Test set shape: (741, 256, 256, 3) (741,)\n",
      "Infection Training set shape: (4123, 256, 256, 3) (4123,)\n",
      "Infection Validation set shape: (1325, 256, 256, 3) (1325,)\n",
      "Infection Test set shape: (442, 256, 256, 3) (442,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, LSTM, Dense, Dropout, BatchNormalization, Reshape\n",
    "from keras.applications import DenseNet121\n",
    "from keras.regularizers import l2\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner.engine.hypermodel import HyperModel\n",
    "\n",
    "# Define the root directory where your image folders are located\n",
    "root_directory = \"PartB_DFU_dataset - Copy\"\n",
    "\n",
    "# Initialize lists to store image paths and corresponding class labels for both datasets\n",
    "image_paths_ischaemia = []\n",
    "categories_ischaemia = []\n",
    "image_paths_infection = []\n",
    "categories_infection = []\n",
    "\n",
    "# Iterate over each class and its subdirectories\n",
    "for class_name in [\"Infection\", \"Ischaemia\"]:\n",
    "    for augmentation_type in [\"Aug-Negative\", \"Aug-Positive\"]:\n",
    "        folder_path = os.path.join(root_directory, class_name, augmentation_type)\n",
    "        category = f\"{class_name.lower()}{'pov' if 'Positive' in augmentation_type else 'neg'}\"\n",
    "        \n",
    "        # Iterate over image files in the current directory\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".jpg\"):  # Assuming images are jpg format\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                if class_name == \"Ischaemia\":\n",
    "                    image_paths_ischaemia.append(image_path)\n",
    "                    categories_ischaemia.append(\"ischemia\" if \"Positive\" in augmentation_type else \"non-ischemia\")\n",
    "                elif class_name == \"Infection\":\n",
    "                    image_paths_infection.append(image_path)\n",
    "                    categories_infection.append(\"infection\" if \"Positive\" in augmentation_type else \"non-infection\")\n",
    "\n",
    "# Create DataFrames for each dataset\n",
    "df_ischaemia = pd.DataFrame({\"category\": categories_ischaemia, \"image_path\": image_paths_ischaemia})\n",
    "df_infection = pd.DataFrame({\"category\": categories_infection, \"image_path\": image_paths_infection})\n",
    "\n",
    "# Label encoding for Ischaemia dataset\n",
    "label_encoder_ischaemia = LabelEncoder()\n",
    "df_ischaemia['Class_Label'] = label_encoder_ischaemia.fit_transform(df_ischaemia['category'])\n",
    "print(\"Ischaemia Class Mapping:\")\n",
    "for class_label, numerical_label in zip(df_ischaemia['category'].unique(), df_ischaemia['Class_Label'].unique()):\n",
    "    print(f\"{class_label}: {numerical_label}\")\n",
    "\n",
    "# Label encoding for Infection dataset\n",
    "label_encoder_infection = LabelEncoder()\n",
    "df_infection['Class_Label'] = label_encoder_infection.fit_transform(df_infection['category'])\n",
    "print(\"Infection Class Mapping:\")\n",
    "for class_label, numerical_label in zip(df_infection['category'].unique(), df_infection['Class_Label'].unique()):\n",
    "    print(f\"{class_label}: {numerical_label}\")\n",
    "\n",
    "# Shuffle both DataFrames\n",
    "df_ischaemia = df_ischaemia.sample(frac=1).reset_index(drop=True)\n",
    "df_infection = df_infection.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Helper function to load and process images\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    target_labels = []   \n",
    "    for index, row in df.iterrows():\n",
    "        image = Image.open(row['image_path']).convert('RGB')\n",
    "        image_array = np.array(image.resize((256, 256)))  # Resize image to fit DenseNet input size\n",
    "        images.append(image_array)\n",
    "        target_labels.append(row['Class_Label'])\n",
    "    return np.array(images), np.array(target_labels)\n",
    "\n",
    "# Load images for both datasets\n",
    "images_ischaemia, target_labels_ischaemia = load_images(df_ischaemia)\n",
    "images_infection, target_labels_infection = load_images(df_infection)\n",
    "\n",
    "print(\"Shape of Ischaemia images array:\", images_ischaemia.shape)\n",
    "print(\"Shape of Ischaemia target labels array:\", target_labels_ischaemia.shape)\n",
    "print(\"Shape of Infection images array:\", images_infection.shape)\n",
    "print(\"Shape of Infection target labels array:\", target_labels_infection.shape)\n",
    "\n",
    "# Split the Ischaemia dataset\n",
    "X_train_ischaemia, X_test_ischaemia, y_train_ischaemia, y_test_ischaemia = train_test_split(\n",
    "    images_ischaemia, target_labels_ischaemia, test_size=0.3, random_state=42)\n",
    "X_val_ischaemia, X_test_ischaemia, y_val_ischaemia, y_test_ischaemia = train_test_split(\n",
    "    X_test_ischaemia, y_test_ischaemia, test_size=0.25, random_state=42)  # 0.25 * 0.3 = 0.075\n",
    "\n",
    "# Split the Infection dataset\n",
    "X_train_infection, X_test_infection, y_train_infection, y_test_infection = train_test_split(\n",
    "    images_infection, target_labels_infection, test_size=0.3, random_state=42)\n",
    "X_val_infection, X_test_infection, y_val_infection, y_test_infection = train_test_split(\n",
    "    X_test_infection, y_test_infection, test_size=0.25, random_state=42)  # 0.25 * 0.3 = 0.075\n",
    "\n",
    "print(\"Ischaemia Training set shape:\", X_train_ischaemia.shape, y_train_ischaemia.shape)\n",
    "print(\"Ischaemia Validation set shape:\", X_val_ischaemia.shape, y_val_ischaemia.shape)\n",
    "print(\"Ischaemia Test set shape:\", X_test_ischaemia.shape, y_test_ischaemia.shape)\n",
    "print(\"Infection Training set shape:\", X_train_infection.shape, y_train_infection.shape)\n",
    "print(\"Infection Validation set shape:\", X_val_infection.shape, y_val_infection.shape)\n",
    "print(\"Infection Test set shape:\", X_test_infection.shape, y_test_infection.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e79104-82b5-40ba-b32f-6ff0586673c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo\n",
      "Successfully installed py-cpuinfo-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install py-cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b93d0af-829d-4931-b77d-e9fb98364684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 08:49:06.115818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22066 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:22:00.0, compute capability: 8.9\n",
      "2024-12-22 08:49:06.118349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22066 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step \n"
     ]
    }
   ],
   "source": [
    "class MyHyperModel(HyperModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "        for layer in self.base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential([\n",
    "            self.base_model,\n",
    "            GlobalAveragePooling2D(),\n",
    "            Reshape((8, 128)),\n",
    "            LSTM(\n",
    "                units=hp.Int('units_lstm1', min_value=16, max_value=32, step=8),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l2(hp.Float('l2_lstm1', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_lstm1', min_value=0.4, max_value=0.5, step=0.1)),\n",
    "            LSTM(\n",
    "                units=hp.Int('units_lstm2', min_value=16, max_value=32, step=8),\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l2(hp.Float('l2_lstm2', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_lstm2', min_value=0.4, max_value=0.5, step=0.1)),\n",
    "            LSTM(\n",
    "                units=hp.Int('units_lstm3', min_value=16, max_value=32, step=8),\n",
    "                kernel_regularizer=l2(hp.Float('l2_lstm3', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            BatchNormalization(),\n",
    "            Dense(\n",
    "                units=hp.Int('units_dense1', min_value=32, max_value=64, step=16),\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(hp.Float('l2_dense1', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_dense1', min_value=0.4, max_value=0.5, step=0.1)),\n",
    "            BatchNormalization(),\n",
    "            Dense(\n",
    "                units=hp.Int('units_dense2', min_value=32, max_value=64, step=16),\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(hp.Float('l2_dense2', min_value=0.001, max_value=0.01, step=0.001))\n",
    "            ),\n",
    "            Dropout(hp.Float('dropout_dense2', min_value=0.4, max_value=0.5, step=0.1)),\n",
    "            BatchNormalization(),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "# Instantiate the HyperModel\n",
    "hypermodel = MyHyperModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad764582-2abd-49c5-b321-dd5e7a585dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVX2 is supported.\n",
      "FMA is supported.\n"
     ]
    }
   ],
   "source": [
    "import cpuinfo\n",
    "\n",
    "info = cpuinfo.get_cpu_info()\n",
    "features = info.get('flags', [])\n",
    "\n",
    "if 'avx2' in features:\n",
    "    print(\"AVX2 is supported.\")\n",
    "else:\n",
    "    print(\"AVX2 is not supported.\")\n",
    "\n",
    "if 'fma' in features:\n",
    "    print(\"FMA is supported.\")\n",
    "else:\n",
    "    print(\"FMA is not supported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8537ef-b7f2-461f-be79-730563a60285",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = BayesianOptimization(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='infection_dir2',\n",
    "    project_name='infection_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a104ba-b036-4371-9c43-e6cdc0d29e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 24s]\n",
      "val_accuracy: 0.7690566182136536\n",
      "\n",
      "Best val_accuracy So Far: 0.7705660462379456\n",
      "Total elapsed time: 00h 32m 11s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "tuner.search(X_train_infection, y_train_infection, epochs=50, validation_data=(X_val_infection, y_val_infection), callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f658e85b-d7f0-4e32-96d8-3d2c1f0c52a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 44 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.7870 - loss: 0.5239\n",
      "Infection Test Accuracy: 0.7828054428100586\n"
     ]
    }
   ],
   "source": [
    "best_model_infection = tuner.get_best_models(num_models=1)[0]\n",
    "test_loss_infection, test_accuracy_infection = best_model_infection.evaluate(X_test_infection, y_test_infection)\n",
    "print(f\"Infection Test Accuracy: {test_accuracy_infection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2c5d3a-f746-4544-9e2a-97fdeb5ac4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 92ms/step - accuracy: 0.3728 - loss: 2.4964 - val_accuracy: 0.4936 - val_loss: 1.6972 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5242 - loss: 1.7755 - val_accuracy: 0.5970 - val_loss: 1.4130 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.6083 - loss: 1.4016 - val_accuracy: 0.6694 - val_loss: 1.2162 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6464 - loss: 1.1891 - val_accuracy: 0.6800 - val_loss: 1.0615 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.6764 - loss: 1.0641 - val_accuracy: 0.7004 - val_loss: 0.9629 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 65ms/step - accuracy: 0.6830 - loss: 0.9794 - val_accuracy: 0.7042 - val_loss: 0.8922 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.6824 - loss: 0.9063 - val_accuracy: 0.7147 - val_loss: 0.8265 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7010 - loss: 0.8366 - val_accuracy: 0.7162 - val_loss: 0.7906 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7111 - loss: 0.7937 - val_accuracy: 0.7253 - val_loss: 0.7508 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7053 - loss: 0.7549 - val_accuracy: 0.7275 - val_loss: 0.7135 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.7232 - loss: 0.7237 - val_accuracy: 0.6740 - val_loss: 0.7350 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7242 - loss: 0.6989 - val_accuracy: 0.7185 - val_loss: 0.6722 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7270 - loss: 0.6903 - val_accuracy: 0.7192 - val_loss: 0.6636 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.7286 - loss: 0.6609 - val_accuracy: 0.7336 - val_loss: 0.6522 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7314 - loss: 0.6477 - val_accuracy: 0.7140 - val_loss: 0.6528 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7403 - loss: 0.6276 - val_accuracy: 0.7532 - val_loss: 0.6137 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.7460 - loss: 0.6054 - val_accuracy: 0.7177 - val_loss: 0.6490 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.7346 - loss: 0.6177 - val_accuracy: 0.7396 - val_loss: 0.6062 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.7458 - loss: 0.6057 - val_accuracy: 0.7381 - val_loss: 0.5931 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7377 - loss: 0.6026 - val_accuracy: 0.7434 - val_loss: 0.5818 - learning_rate: 0.0010\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7485 - loss: 0.5713\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.7751 - loss: 0.5590\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Training Accuracy: 0.7487266659736633\n",
      "Training Loss: 0.5901035070419312\n",
      "Training F1 Score: 0.7864847929321961\n",
      "Training Precision: 0.7869550607760636\n",
      "Training Recall: 0.7865496566881109\n",
      "Training Time (s): 202.48869395256042\n",
      "Validation Accuracy: 0.7433962225914001\n",
      "Validation Loss: 0.5818286538124084\n",
      "Validation F1 Score: 0.7433633359917968\n",
      "Validation Precision: 0.7439307044078529\n",
      "Validation Recall: 0.7436638911296755\n",
      "Validation Time (s): 7.707524538040161\n",
      "Test Accuracy: 0.7556561231613159\n",
      "Test F1 Score: 0.755656108597285\n",
      "Test Precision: 0.756414986063289\n",
      "Test Recall: 0.756414986063289\n",
      "Testing Time (s): 1.5359735488891602\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Start time for training\n",
    "start_training_time = time.time()\n",
    "\n",
    "# Get the best hyperparameters and build the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Fit the model and collect the training metrics\n",
    "history = best_model.fit(X_train_infection, y_train_infection, epochs=20, batch_size=32, \n",
    "                         validation_data=(X_val_infection, y_val_infection), \n",
    "                         callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Collect training metrics\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "train_f1 = f1_score(y_train_infection, np.argmax(best_model.predict(X_train_infection), axis=1), average='macro')\n",
    "train_precision = precision_score(y_train_infection, np.argmax(best_model.predict(X_train_infection), axis=1), average='macro')\n",
    "train_recall = recall_score(y_train_infection, np.argmax(best_model.predict(X_train_infection), axis=1), average='macro')\n",
    "\n",
    "# End time for training\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "\n",
    "# Start time for validation\n",
    "start_validation_time = time.time()\n",
    "\n",
    "# Validate the model\n",
    "val_loss, val_accuracy = best_model.evaluate(X_val_infection, y_val_infection)\n",
    "\n",
    "# Collect validation metrics\n",
    "val_f1 = f1_score(y_val_infection, np.argmax(best_model.predict(X_val_infection), axis=1), average='macro')\n",
    "val_precision = precision_score(y_val_infection, np.argmax(best_model.predict(X_val_infection), axis=1), average='macro')\n",
    "val_recall = recall_score(y_val_infection, np.argmax(best_model.predict(X_val_infection), axis=1), average='macro')\n",
    "\n",
    "# End time for validation\n",
    "end_validation_time = time.time()\n",
    "validation_time = end_validation_time - start_validation_time\n",
    "\n",
    "# Start time for testing\n",
    "start_testing_time = time.time()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_infection, y_test_infection)\n",
    "\n",
    "# Predictions for classification metrics\n",
    "y_pred = best_model.predict(X_test_infection)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Collect testing metrics\n",
    "test_f1 = f1_score(y_test_infection, y_pred_classes, average='macro')\n",
    "test_precision = precision_score(y_test_infection, y_pred_classes, average='macro')\n",
    "test_recall = recall_score(y_test_infection, y_pred_classes, average='macro')\n",
    "\n",
    "# End time for testing\n",
    "end_testing_time = time.time()\n",
    "testing_time = end_testing_time - start_testing_time\n",
    "\n",
    "# Collect all metrics in a dictionary for easy access\n",
    "metrics = {\n",
    "    'Training Accuracy': train_accuracy,\n",
    "    'Training Loss': train_loss,\n",
    "    'Training F1 Score': train_f1,\n",
    "    'Training Precision': train_precision,\n",
    "    'Training Recall': train_recall,\n",
    "    'Training Time (s)': training_time,\n",
    "    'Validation Accuracy': val_accuracy,\n",
    "    'Validation Loss': val_loss,\n",
    "    'Validation F1 Score': val_f1,\n",
    "    'Validation Precision': val_precision,\n",
    "    'Validation Recall': val_recall,\n",
    "    'Validation Time (s)': validation_time,\n",
    "    'Test Accuracy': test_accuracy,\n",
    "    'Test F1 Score': test_f1,\n",
    "    'Test Precision': test_precision,\n",
    "    'Test Recall': test_recall,\n",
    "    'Testing Time (s)': testing_time\n",
    "}\n",
    "\n",
    "# Print the collected metrics\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6060b-79a8-4bc7-ba16-e7515cb50671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
