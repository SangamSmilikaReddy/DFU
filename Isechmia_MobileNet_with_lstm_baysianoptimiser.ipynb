{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46002e6-eaad-47a9-8292-2188203ece6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 05:41:11.760167: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed successfully to 'DFU_dataset'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile as zf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "# Path to the repaired ZIP file\n",
    "zip_file_path = \"PartB_DFU_dataset - Copy.zip\"\n",
    "extract_path = \"DFU_dataset\"\n",
    "\n",
    "if os.path.exists(zip_file_path):\n",
    "    try:\n",
    "        with zf.ZipFile(zip_file_path, 'r') as files:\n",
    "            files.extractall(extract_path)\n",
    "        print(f\"Extraction completed successfully to '{extract_path}'\")\n",
    "    except zf.BadZipFile:\n",
    "        print(\"Error: The ZIP file is corrupted.\")\n",
    "    except OSError as e:\n",
    "        print(f\"OS error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "else:\n",
    "    print(f\"Error: The file '{zip_file_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84251448-be88-4fd5-bc82-10122731381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ischaemia Class Mapping:\n",
      "non-ischemia: 1\n",
      "ischemia: 0\n",
      "Infection Class Mapping:\n",
      "non-infection: 1\n",
      "infection: 0\n",
      "Shape of Ischaemia images array: (9870, 224, 224, 3)\n",
      "Shape of Ischaemia target labels array: (9870,)\n",
      "Shape of Infection images array: (5890, 224, 224, 3)\n",
      "Shape of Infection target labels array: (5890,)\n",
      "Ischaemia Training set shape: (6909, 224, 224, 3) (6909,)\n",
      "Ischaemia Validation set shape: (2220, 224, 224, 3) (2220,)\n",
      "Ischaemia Test set shape: (741, 224, 224, 3) (741,)\n",
      "Infection Training set shape: (4123, 224, 224, 3) (4123,)\n",
      "Infection Validation set shape: (1325, 224, 224, 3) (1325,)\n",
      "Infection Test set shape: (442, 224, 224, 3) (442,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# Define the root directory where your image folders are located\n",
    "root_directory = \"DFU_dataset/PartB_DFU_dataset - Copy\"\n",
    "\n",
    "# Initialize lists to store image paths and corresponding class labels for both datasets\n",
    "image_paths_ischaemia = []\n",
    "categories_ischaemia = []\n",
    "image_paths_infection = []\n",
    "categories_infection = []\n",
    "\n",
    "# Iterate over each class and its subdirectories\n",
    "for class_name in [\"Infection\", \"Ischaemia\"]:\n",
    "    for augmentation_type in [\"Aug-Negative\", \"Aug-Positive\"]:\n",
    "        folder_path = os.path.join(root_directory, class_name, augmentation_type)\n",
    "        category = f\"{class_name.lower()}{'pov' if 'Positive' in augmentation_type else 'neg'}\"\n",
    "        \n",
    "        # Iterate over image files in the current directory\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".jpg\"):  # Assuming images are jpg format\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                if class_name == \"Ischaemia\":\n",
    "                    image_paths_ischaemia.append(image_path)\n",
    "                    categories_ischaemia.append(\"ischemia\" if \"Positive\" in augmentation_type else \"non-ischemia\")\n",
    "                elif class_name == \"Infection\":\n",
    "                    image_paths_infection.append(image_path)\n",
    "                    categories_infection.append(\"infection\" if \"Positive\" in augmentation_type else \"non-infection\")\n",
    "\n",
    "# Create DataFrames for each dataset\n",
    "df_ischaemia = pd.DataFrame({\"category\": categories_ischaemia, \"image_path\": image_paths_ischaemia})\n",
    "df_infection = pd.DataFrame({\"category\": categories_infection, \"image_path\": image_paths_infection})\n",
    "\n",
    "# Label encoding for Ischaemia dataset\n",
    "label_encoder_ischaemia = LabelEncoder()\n",
    "df_ischaemia['Class_Label'] = label_encoder_ischaemia.fit_transform(df_ischaemia['category'])\n",
    "print(\"Ischaemia Class Mapping:\")\n",
    "for class_label, numerical_label in zip(df_ischaemia['category'].unique(), df_ischaemia['Class_Label'].unique()):\n",
    "    print(f\"{class_label}: {numerical_label}\")\n",
    "\n",
    "# Label encoding for Infection dataset\n",
    "label_encoder_infection = LabelEncoder()\n",
    "df_infection['Class_Label'] = label_encoder_infection.fit_transform(df_infection['category'])\n",
    "print(\"Infection Class Mapping:\")\n",
    "for class_label, numerical_label in zip(df_infection['category'].unique(), df_infection['Class_Label'].unique()):\n",
    "    print(f\"{class_label}: {numerical_label}\")\n",
    "\n",
    "# Shuffle both DataFrames\n",
    "df_ischaemia = df_ischaemia.sample(frac=1).reset_index(drop=True)\n",
    "df_infection = df_infection.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Helper function to load and process images\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    target_labels = []   \n",
    "    for index, row in df.iterrows():\n",
    "        image = Image.open(row['image_path'])\n",
    "        image_array = np.array(image.resize((224, 224)))  # Resize image to fit MobileNet input size\n",
    "        images.append(image_array)\n",
    "        target_labels.append(row['Class_Label'])\n",
    "    return np.array(images), np.array(target_labels)\n",
    "\n",
    "# Load images for both datasets\n",
    "images_ischaemia, target_labels_ischaemia = load_images(df_ischaemia)\n",
    "images_infection, target_labels_infection = load_images(df_infection)\n",
    "\n",
    "print(\"Shape of Ischaemia images array:\", images_ischaemia.shape)\n",
    "print(\"Shape of Ischaemia target labels array:\", target_labels_ischaemia.shape)\n",
    "print(\"Shape of Infection images array:\", images_infection.shape)\n",
    "print(\"Shape of Infection target labels array:\", target_labels_infection.shape)\n",
    "\n",
    "# Split the Ischaemia dataset\n",
    "X_train_ischaemia, X_test_ischaemia, y_train_ischaemia, y_test_ischaemia = train_test_split(\n",
    "    images_ischaemia, target_labels_ischaemia, test_size=0.3, random_state=42)\n",
    "X_val_ischaemia, X_test_ischaemia, y_val_ischaemia, y_test_ischaemia = train_test_split(\n",
    "    X_test_ischaemia, y_test_ischaemia, test_size=0.25, random_state=42)  # 0.25 * 0.3 = 0.075\n",
    "\n",
    "# Split the Infection dataset\n",
    "X_train_infection, X_test_infection, y_train_infection, y_test_infection = train_test_split(\n",
    "    images_infection, target_labels_infection, test_size=0.3, random_state=42)\n",
    "X_val_infection, X_test_infection, y_val_infection, y_test_infection = train_test_split(\n",
    "    X_test_infection, y_test_infection, test_size=0.25, random_state=42)  # 0.25 * 0.3 = 0.075\n",
    "\n",
    "print(\"Ischaemia Training set shape:\", X_train_ischaemia.shape, y_train_ischaemia.shape)\n",
    "print(\"Ischaemia Validation set shape:\", X_val_ischaemia.shape, y_val_ischaemia.shape)\n",
    "print(\"Ischaemia Test set shape:\", X_test_ischaemia.shape, y_test_ischaemia.shape)\n",
    "print(\"Infection Training set shape:\", X_train_infection.shape, y_train_infection.shape)\n",
    "print(\"Infection Validation set shape:\", X_val_infection.shape, y_val_infection.shape)\n",
    "print(\"Infection Test set shape:\", X_test_infection.shape, y_test_infection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1543374a-8801-4ec1-a6a0-405ce790e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 17m 46s]\n",
      "val_accuracy: 0.8279279470443726\n",
      "\n",
      "Best val_accuracy So Far: 0.8310810923576355\n",
      "Total elapsed time: 01h 29m 12s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from kerastuner import HyperModel, HyperParameters\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dropout, TimeDistributed, Flatten, LSTM, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        TimeDistributed(Flatten()),\n",
    "        LSTM(hp.Int('lstm_units_1', min_value=60, max_value=80, step=30), \n",
    "             dropout=hp.Float('dropout_1', min_value=0.2, max_value=0.3, step=0.1), \n",
    "             return_sequences=True),\n",
    "        LSTM(hp.Int('lstm_units_2', min_value=30, max_value=60, step=10), \n",
    "             dropout=hp.Float('dropout_2', min_value=0.2, max_value=0.3, step=0.1), \n",
    "             return_sequences=True),\n",
    "        LSTM(hp.Int('lstm_units_3', min_value=10, max_value=30, step=10), \n",
    "             dropout=0.2, \n",
    "             return_sequences=False),\n",
    "        Dense(84, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='LSTM_mobileNetV2_tuning',\n",
    "    project_name='Bay_ischaemia_tuning'  # Updated project name\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Run the search and log trial results\n",
    "tuner.search(X_train_ischaemia, y_train_ischaemia, epochs=10,  # Updated variable names\n",
    "             validation_data=(X_val_ischaemia, y_val_ischaemia),  # Updated variable names\n",
    "             callbacks=[reduce_lr, early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84899872-d5a2-4800-bb25-a7b1ab9e8976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 498ms/step - accuracy: 0.6892 - loss: 0.6894 - val_accuracy: 0.7838 - val_loss: 0.4868 - learning_rate: 0.0050\n",
      "Epoch 2/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 493ms/step - accuracy: 0.7696 - loss: 0.4780 - val_accuracy: 0.7986 - val_loss: 0.4230 - learning_rate: 0.0050\n",
      "Epoch 3/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 488ms/step - accuracy: 0.7813 - loss: 0.4713 - val_accuracy: 0.8077 - val_loss: 0.4165 - learning_rate: 0.0050\n",
      "Epoch 4/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 488ms/step - accuracy: 0.7898 - loss: 0.4658 - val_accuracy: 0.7901 - val_loss: 0.4293 - learning_rate: 0.0050\n",
      "Epoch 5/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 489ms/step - accuracy: 0.7972 - loss: 0.4432 - val_accuracy: 0.8153 - val_loss: 0.3893 - learning_rate: 0.0050\n",
      "Epoch 6/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 490ms/step - accuracy: 0.8040 - loss: 0.4272 - val_accuracy: 0.8216 - val_loss: 0.3817 - learning_rate: 0.0050\n",
      "Epoch 7/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 491ms/step - accuracy: 0.8139 - loss: 0.4190 - val_accuracy: 0.7955 - val_loss: 0.4543 - learning_rate: 0.0050\n",
      "Epoch 8/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 489ms/step - accuracy: 0.7898 - loss: 0.4512 - val_accuracy: 0.8135 - val_loss: 0.3980 - learning_rate: 0.0050\n",
      "Epoch 9/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 487ms/step - accuracy: 0.8145 - loss: 0.4080 - val_accuracy: 0.8149 - val_loss: 0.3804 - learning_rate: 1.0000e-03\n",
      "Epoch 10/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 489ms/step - accuracy: 0.8041 - loss: 0.4042 - val_accuracy: 0.8194 - val_loss: 0.3739 - learning_rate: 1.0000e-03\n",
      "Epoch 11/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 487ms/step - accuracy: 0.8164 - loss: 0.3930 - val_accuracy: 0.8171 - val_loss: 0.3751 - learning_rate: 1.0000e-03\n",
      "Epoch 12/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 489ms/step - accuracy: 0.8217 - loss: 0.3905 - val_accuracy: 0.8216 - val_loss: 0.3728 - learning_rate: 1.0000e-03\n",
      "Epoch 13/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 488ms/step - accuracy: 0.8312 - loss: 0.3805 - val_accuracy: 0.8122 - val_loss: 0.3822 - learning_rate: 1.0000e-03\n",
      "Epoch 14/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 491ms/step - accuracy: 0.8210 - loss: 0.3877 - val_accuracy: 0.8230 - val_loss: 0.3758 - learning_rate: 1.0000e-03\n",
      "Epoch 15/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 488ms/step - accuracy: 0.8294 - loss: 0.3698 - val_accuracy: 0.8270 - val_loss: 0.3757 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 489ms/step - accuracy: 0.8279 - loss: 0.3701 - val_accuracy: 0.8279 - val_loss: 0.3708 - learning_rate: 2.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 490ms/step - accuracy: 0.8311 - loss: 0.3640 - val_accuracy: 0.8275 - val_loss: 0.3681 - learning_rate: 2.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 488ms/step - accuracy: 0.8317 - loss: 0.3636 - val_accuracy: 0.8275 - val_loss: 0.3707 - learning_rate: 2.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 490ms/step - accuracy: 0.8300 - loss: 0.3612 - val_accuracy: 0.8302 - val_loss: 0.3686 - learning_rate: 2.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 487ms/step - accuracy: 0.8477 - loss: 0.3545 - val_accuracy: 0.8306 - val_loss: 0.3686 - learning_rate: 4.0000e-05\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 355ms/step \n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 353ms/step \n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 354ms/step \n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 353ms/step - accuracy: 0.8155 - loss: 0.3926\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 349ms/step\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 346ms/step\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 349ms/step\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.8481 - loss: 0.3492\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 339ms/step\n",
      "Training Accuracy: 0.8418005704879761\n",
      "Training Loss: 0.3597659468650818\n",
      "Training F1 Score: 0.8519307609239634\n",
      "Training Precision: 0.8519310402387618\n",
      "Training Recall: 0.8519433678450368\n",
      "Training Time (s): 2352.8845920562744\n",
      "Validation Accuracy: 0.8306306600570679\n",
      "Validation Loss: 0.36856526136398315\n",
      "Validation F1 Score: 0.8305996955859969\n",
      "Validation Precision: 0.831030770793135\n",
      "Validation Recall: 0.8307083578515918\n",
      "Validation Time (s): 98.48635172843933\n",
      "Test Accuracy: 0.8340080976486206\n",
      "Test F1 Score: 0.833570412517781\n",
      "Test Precision: 0.8332263663812594\n",
      "Test Recall: 0.8344312692138779\n",
      "Testing Time (s): 16.595171213150024\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Start time for training\n",
    "start_training_time = time.time()\n",
    "\n",
    "# Get the best hyperparameters and build the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Fit the model and collect the training metrics\n",
    "history = best_model.fit(X_train_ischaemia, y_train_ischaemia, epochs=20, batch_size=32, \n",
    "                         validation_data=(X_val_ischaemia, y_val_ischaemia), \n",
    "                         callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Collect training metrics\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "train_f1 = f1_score(y_train_ischaemia, np.argmax(best_model.predict(X_train_ischaemia), axis=1), average='macro')\n",
    "train_precision = precision_score(y_train_ischaemia, np.argmax(best_model.predict(X_train_ischaemia), axis=1), average='macro')\n",
    "train_recall = recall_score(y_train_ischaemia, np.argmax(best_model.predict(X_train_ischaemia), axis=1), average='macro')\n",
    "\n",
    "# End time for training\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "\n",
    "# Start time for validation\n",
    "start_validation_time = time.time()\n",
    "\n",
    "# Validate the model\n",
    "val_loss, val_accuracy = best_model.evaluate(X_val_ischaemia, y_val_ischaemia)\n",
    "\n",
    "# Collect validation metrics\n",
    "val_f1 = f1_score(y_val_ischaemia, np.argmax(best_model.predict(X_val_ischaemia), axis=1), average='macro')\n",
    "val_precision = precision_score(y_val_ischaemia, np.argmax(best_model.predict(X_val_ischaemia), axis=1), average='macro')\n",
    "val_recall = recall_score(y_val_ischaemia, np.argmax(best_model.predict(X_val_ischaemia), axis=1), average='macro')\n",
    "\n",
    "# End time for validation\n",
    "end_validation_time = time.time()\n",
    "validation_time = end_validation_time - start_validation_time\n",
    "\n",
    "# Start time for testing\n",
    "start_testing_time = time.time()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test_ischaemia, y_test_ischaemia)\n",
    "\n",
    "# Predictions for classification metrics\n",
    "y_pred = best_model.predict(X_test_ischaemia)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Collect testing metrics\n",
    "test_f1 = f1_score(y_test_ischaemia, y_pred_classes, average='macro')\n",
    "test_precision = precision_score(y_test_ischaemia, y_pred_classes, average='macro')\n",
    "test_recall = recall_score(y_test_ischaemia, y_pred_classes, average='macro')\n",
    "\n",
    "# End time for testing\n",
    "end_testing_time = time.time()\n",
    "testing_time = end_testing_time - start_testing_time\n",
    "\n",
    "# Collect all metrics in a dictionary for easy access\n",
    "metrics = {\n",
    "    'Training Accuracy': train_accuracy,\n",
    "    'Training Loss': train_loss,\n",
    "    'Training F1 Score': train_f1,\n",
    "    'Training Precision': train_precision,\n",
    "    'Training Recall': train_recall,\n",
    "    'Training Time (s)': training_time,\n",
    "    'Validation Accuracy': val_accuracy,\n",
    "    'Validation Loss': val_loss,\n",
    "    'Validation F1 Score': val_f1,\n",
    "    'Validation Precision': val_precision,\n",
    "    'Validation Recall': val_recall,\n",
    "    'Validation Time (s)': validation_time,\n",
    "    'Test Accuracy': test_accuracy,\n",
    "    'Test F1 Score': test_f1,\n",
    "    'Test Precision': test_precision,\n",
    "    'Test Recall': test_recall,\n",
    "    'Testing Time (s)': testing_time\n",
    "}\n",
    "\n",
    "# Print the collected metrics\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780082d7-6486-4344-b332-ccd171dba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tf.keras.utils.plot_model(best_model, to_file='best_model_isechamia_inceotionv3.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Extract best hyperparameters as a dictionary\n",
    "best_params = best_hps.values\n",
    "\n",
    "# Convert the best hyperparameters dictionary to an array\n",
    "best_params_array = list(best_params.values())\n",
    "\n",
    "# Print the best parameters as an array\n",
    "print(\"Best Hyperparameters:\", best_params_array)\n",
    "\n",
    "\n",
    "# Plot training, validation, and test accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Training accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "# Validation accuracy\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "# Test accuracy\n",
    "plt.plot([0, len(history.history['accuracy']) - 1], [metrics['Test Accuracy']] * 2, label='Test Accuracy', linestyle='--', color='green')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training, Validation, and Test Accuracy ')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3b239-3bfb-4cd1-b494-9153df9a3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test and y_pred_classes are already defined\n",
    "cm = confusion_matrix(y_test_ischaemia, y_pred_classes)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test_ischaemia), yticklabels=np.unique(y_test_ischaemia))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820ff98-957e-46f6-82fa-a3a19388756f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
